{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AndrewKrugTech/analyticspractice/blob/main/Dirty%20vs%20Cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-25T06:25:12.556308Z",
     "iopub.status.busy": "2022-12-25T06:25:12.555877Z",
     "iopub.status.idle": "2022-12-25T06:25:12.563145Z",
     "shell.execute_reply": "2022-12-25T06:25:12.561972Z",
     "shell.execute_reply.started": "2022-12-25T06:25:12.556274Z"
    },
    "id": "eGrKMm1P5j4O"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import copy\n",
    "import shutil \n",
    "import zipfile\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/home/andrew/analyticspractice/dirtycleaned/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8MZilJIgi5T",
    "outputId": "8dedd84b-3f25-4bcb-a653-0d9a2399f97d"
   },
   "outputs": [],
   "source": [
    "! mkdir -p ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle datasets download andrewkrug/plates\n",
    "! unzip plates.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oC18iO_g5j4S"
   },
   "source": [
    "## Prepare some Classes and Functions for pictures transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T15:31:05.317550Z",
     "iopub.status.busy": "2022-12-24T15:31:05.316662Z",
     "iopub.status.idle": "2022-12-24T15:31:05.327122Z",
     "shell.execute_reply": "2022-12-24T15:31:05.326462Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.317519Z"
    },
    "id": "yRf3E8F75j4S"
   },
   "outputs": [],
   "source": [
    "class RemoveBackground:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, in_img):\n",
    "        in_img = np.array(in_img)\n",
    "        height, width = in_img.shape[:2]\n",
    "        mask = np.zeros([height, width], np.uint8)\n",
    "\n",
    "        bgdModel = np.zeros((1, 65),np.float64)\n",
    "        fgdModel = np.zeros((1, 65),np.float64)\n",
    "\n",
    "        rect = (15, 15, width-30, height-30)\n",
    "        cv2.grabCut(in_img, mask, rect, bgdModel, fgdModel, 10, cv2.GC_INIT_WITH_RECT)\n",
    "        mask = np.where((mask==2)|(mask==0), 0, 1).astype('uint8')\n",
    "        out_img = in_img * mask[:, :, np.newaxis]\n",
    "\n",
    "        background = in_img - out_img\n",
    "\n",
    "        background[np.where((background > [0, 0, 0]).all(axis = 2))] = [255, 255, 255]\n",
    "\n",
    "        out_img = background + out_img\n",
    "\n",
    "        return transforms.functional.to_pil_image(out_img)\n",
    "    \n",
    "\n",
    "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T15:31:05.329106Z",
     "iopub.status.busy": "2022-12-24T15:31:05.328547Z",
     "iopub.status.idle": "2022-12-24T15:31:05.361803Z",
     "shell.execute_reply": "2022-12-24T15:31:05.360458Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.329072Z"
    },
    "id": "N7bLmyf25j4S"
   },
   "outputs": [],
   "source": [
    "def unzip_data(zip_file, destination_dir):\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_obj:\n",
    "        zip_obj.extractall(destination_dir)\n",
    "    print(f'Files unzipped to \\'{destination_dir}\\'\\n')\n",
    "\n",
    "def remove_background(image_roots):\n",
    "    remove_photo_background = RemoveBackground()\n",
    "\n",
    "    for path in image_roots:\n",
    "        files = os.listdir(path)\n",
    "        files = list(filter(lambda x: x.endswith('.jpg'), files))\n",
    "        \n",
    "        print(f'{len(files)} pictures was found in {path}', end='')\n",
    "        for i, file in enumerate(files):\n",
    "            img_original = cv2.imread(path + file)\n",
    "            img_cleaned = remove_photo_background(img_original)\n",
    "            img_cleaned = np.array(img_cleaned)\n",
    "            cv2.imwrite(path + file, img_cleaned)\n",
    "            if i % 20 == 0:\n",
    "                print('\\n{:>3d}/{:>3d}'.format(i, len(files)), end='')\n",
    "            print('.', end='')\n",
    "        print()\n",
    "    \n",
    "def make_extra_images(image_roots):\n",
    "    prefix_names = ['_090', '_180', '_270']\n",
    "\n",
    "    for path in image_roots:\n",
    "        files = os.listdir(path)\n",
    "        files = list(filter(lambda x: x.endswith('.jpg') and '_' not in x, files))\n",
    "\n",
    "        for i, file in enumerate(files):\n",
    "            img = cv2.imread(path + file)\n",
    "            # Make extra pictures: flip each of originals photo to 90, 180 and 270 degrees\n",
    "            for i, angle in enumerate([cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180, cv2.ROTATE_90_COUNTERCLOCKWISE]):\n",
    "                img = cv2.rotate(img, angle)\n",
    "                img_name = path + file[:file.find('.')] + prefix_names[i] + file[file.find('.'):]\n",
    "                if not os.path.exists(img_name):\n",
    "                    cv2.imwrite(img_name, img)\n",
    "\n",
    "    for path in image_roots:\n",
    "        files = os.listdir(path)\n",
    "        files = list(filter(lambda x: x.endswith('.jpg'), files))\n",
    "        print(f'{len(files)} pictures added to \\'{path}\\'')\n",
    "    print()\n",
    "    \n",
    "\n",
    "def make_train_valid_data():\n",
    "    for dir_name in [train_dir, valid_dir]:\n",
    "        for class_name in class_names:\n",
    "            os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n",
    "\n",
    "    for class_name in class_names:\n",
    "        src_dir = os.path.join(data_root, 'train', class_name)\n",
    "        files = os.listdir(src_dir)\n",
    "        files = list(filter(lambda x: x.endswith('.jpg'), files))\n",
    "        \n",
    "        for i, file_name in enumerate(files):\n",
    "            if i % 6 != 0:\n",
    "                dst_dir = os.path.join(train_dir, class_name) \n",
    "            else:\n",
    "                dst_dir = os.path.join(valid_dir, class_name)\n",
    "            shutil.copy(os.path.join(src_dir, file_name), os.path.join(dst_dir, file_name))\n",
    "\n",
    "    for dir_name in [train_dir, valid_dir]:\n",
    "        for class_name in class_names:\n",
    "            dst_dir = os.path.join(dir_name, class_name)\n",
    "            files = os.listdir(dst_dir)\n",
    "            files = list(filter(lambda x: x.endswith('.jpg'), files))\n",
    "            print(f'{len(files)} pictures copied to \\'{dst_dir}\\'')\n",
    "    print()\n",
    "    \n",
    "\n",
    "def make_test_data():\n",
    "    src_dir = os.path.join(data_root, 'test')\n",
    "    dst_dir = os.path.join(test_dir, 'unknown')\n",
    "    print(src_dir, dst_dir)\n",
    "    shutil.copytree(src_dir, dst_dir)\n",
    "    files = os.listdir(dst_dir)\n",
    "    files = list(filter(lambda x: x.endswith('.jpg'), files))\n",
    "    print(f'{len(files)} pictures copied to \\'{dst_dir}\\'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9v1-vEoz5j4T"
   },
   "source": [
    "# **Unzip data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hHAg8ds5j4U"
   },
   "source": [
    "## Ok. Let's start :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2022-12-24T15:44:44.804669Z",
     "iopub.status.busy": "2022-12-24T15:44:44.804259Z",
     "iopub.status.idle": "2022-12-24T15:44:48.203745Z",
     "shell.execute_reply": "2022-12-24T15:44:48.202697Z",
     "shell.execute_reply.started": "2022-12-24T15:44:44.804635Z"
    },
    "id": "jkcqtAv75j4U",
    "outputId": "6fa08253-3b54-416f-c3d9-950c06731f70"
   },
   "outputs": [],
   "source": [
    "# Clear output directory\n",
    "#!rm * --recursive\n",
    "shutil.make_archive('plates','zip',DATA_ROOT + '/plates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-24T15:46:13.092214Z",
     "iopub.status.busy": "2022-12-24T15:46:13.091833Z",
     "iopub.status.idle": "2022-12-24T15:46:13.448571Z",
     "shell.execute_reply": "2022-12-24T15:46:13.446564Z",
     "shell.execute_reply.started": "2022-12-24T15:46:13.092183Z"
    },
    "id": "_UBSDPC_5j4V",
    "outputId": "aa2e8275-83d9-440d-9100-07c0d9ad9536"
   },
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "# Let's define some variables\n",
    "class_names = ['cleaned', 'dirty']\n",
    "train_dir = 'train'\n",
    "valid_dir = 'valid'\n",
    "test_dir = 'test'\n",
    "\n",
    "# Extract images (Kaggle enviropment)\n",
    "data_root = DATA_ROOT + '/working'\n",
    "\n",
    "unzip_data(zip_file=DATA_ROOT + '/plates.zip', destination_dir=DATA_ROOT + '/working/')\n",
    "os.remove(DATA_ROOT + '/plates.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-24T15:46:32.698708Z",
     "iopub.status.busy": "2022-12-24T15:46:32.698371Z",
     "iopub.status.idle": "2022-12-24T15:58:38.379823Z",
     "shell.execute_reply": "2022-12-24T15:58:38.378614Z",
     "shell.execute_reply.started": "2022-12-24T15:46:32.698684Z"
    },
    "id": "0AP6zTHV5j4V",
    "outputId": "5a02e11f-23ae-48b2-8986-237e28978ae9"
   },
   "outputs": [],
   "source": [
    "# Remove images background \n",
    "remove_background(image_roots=[os.path.join(data_root, train_dir, 'cleaned/'),\n",
    "                               os.path.join(data_root, train_dir, 'dirty/'),\n",
    "                               os.path.join(data_root, 'test/')])\n",
    "\n",
    "# Create extra images for training models\n",
    "make_extra_images(image_roots=[os.path.join(data_root, train_dir, 'cleaned/'),\n",
    "                               os.path.join(data_root, train_dir, 'dirty/')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-24T17:10:13.858673Z",
     "iopub.status.busy": "2022-12-24T17:10:13.857982Z",
     "iopub.status.idle": "2022-12-24T17:10:13.900044Z",
     "shell.execute_reply": "2022-12-24T17:10:13.898934Z",
     "shell.execute_reply.started": "2022-12-24T17:10:13.858551Z"
    },
    "id": "F3jW6y135j4V",
    "outputId": "2b32c92c-d785-4bf8-88e0-ce17a5fef70f"
   },
   "outputs": [],
   "source": [
    "def my_same_file_diff_checker(*args, **kwargs):#нереальный костыль\n",
    "    return False\n",
    "\n",
    "shutil._samefile = my_same_file_diff_checker\n",
    "\n",
    "make_train_valid_data()\n",
    "make_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3k4lG_eN5j4W"
   },
   "source": [
    "## Load data into Datasets\n",
    "* Create Train, Valid transformation methods (*Test transformations methods will be defined later*)\n",
    "* Create Train, Valid and Test datasets\n",
    "* Create Train, Valid and Test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-24T17:12:33.806489Z",
     "iopub.status.busy": "2022-12-24T17:12:33.806060Z",
     "iopub.status.idle": "2022-12-24T17:12:33.833147Z",
     "shell.execute_reply": "2022-12-24T17:12:33.830743Z",
     "shell.execute_reply.started": "2022-12-24T17:12:33.806455Z"
    },
    "id": "3hXIMsBw5j4W",
    "outputId": "7e3c7e65-43f4-4ad0-d404-0abbae485aff"
   },
   "outputs": [],
   "source": [
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomPerspective(distortion_scale=0.2, p=0.1, interpolation=3, fill=255),\n",
    "        transforms.RandomChoice([transforms.CenterCrop(180),\n",
    "                                 transforms.CenterCrop(160),\n",
    "                                 transforms.CenterCrop(140),\n",
    "                                 transforms.CenterCrop(120),\n",
    "                                 transforms.Compose([transforms.CenterCrop(280),\n",
    "                                                     transforms.Grayscale(3),\n",
    "                                                     ]),\n",
    "                                 transforms.Compose([transforms.CenterCrop(200),\n",
    "                                                     transforms.Grayscale(3),\n",
    "                                                     ]),\n",
    "                                 ]),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ColorJitter(hue=(0.1, 0.2)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.RandomPerspective(distortion_scale=0.2, p=0.1, interpolation=3, fill=255),\n",
    "        transforms.RandomChoice([transforms.CenterCrop(180),\n",
    "                                 transforms.CenterCrop(160),\n",
    "                                 transforms.CenterCrop(140),\n",
    "                                 transforms.CenterCrop(120),\n",
    "                                 transforms.Compose([transforms.CenterCrop(280),\n",
    "                                                     transforms.Grayscale(3),\n",
    "                                                     ]),\n",
    "                                 transforms.Compose([transforms.CenterCrop(200),\n",
    "                                                     transforms.Grayscale(3),\n",
    "                                                     ]),\n",
    "                                 ]),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ColorJitter(hue=(0.1, 0.2)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),}\n",
    "\n",
    "dataset = {\n",
    "    'train': torchvision.datasets.ImageFolder(root=train_dir, transform=image_transforms['train']),\n",
    "    'valid': torchvision.datasets.ImageFolder(root=valid_dir, transform=image_transforms['valid']),\n",
    "    'test': ImageFolderWithPaths(DATA_ROOT + '/test', transform=None),\n",
    "}\n",
    " \n",
    "batch_size = 12\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset['train'],\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=batch_size)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset['valid'],\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=batch_size)\n",
    "\n",
    "test_dataloader  = torch.utils.data.DataLoader(dataset['test'],\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0)\n",
    "\n",
    "print('{:<7s}{:>10s}{:>10s}'.format('Dataset', 'Batches', 'Pictures')), print('-' * 28)\n",
    "print('{:<7s}{:>10d}{:>10d}'.format('Train', len(train_dataloader), len(dataset['train'])))\n",
    "print('{:<7s}{:>10d}{:>10d}'.format('Valid', len(valid_dataloader), len(dataset['valid'])))\n",
    "print('{:<7s}{:>10d}{:>10d}'.format('Test',  len(test_dataloader),  len(dataset['test'])))\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh3Zd3VC5j4W"
   },
   "source": [
    "## Load some images from batches\n",
    "It's just for check what we have in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "execution": {
     "iopub.execute_input": "2022-12-24T18:24:42.879638Z",
     "iopub.status.busy": "2022-12-24T18:24:42.879153Z",
     "iopub.status.idle": "2022-12-24T18:24:42.911474Z",
     "shell.execute_reply": "2022-12-24T18:24:42.910056Z",
     "shell.execute_reply.started": "2022-12-24T18:24:42.879547Z"
    },
    "id": "a1N4VSvM5j4W",
    "outputId": "3bbefea9-f9bd-4948-bf77-c10d429f1820"
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "\n",
    "image_iter = iter(train_dataloader)\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "for i in range(3):\n",
    "    X_batch, y_batch = next(image_iter)\n",
    "    for j in range(0, len(X_batch)):\n",
    "        try:\n",
    "            plt.subplot(3, 4, i*batch_size + j + 1)\n",
    "        except ValueError:\n",
    "            None \n",
    "        plt.title(class_names[y_batch[j].item()])\n",
    "        plt.imshow(((X_batch[j].permute(1, 2, 0).numpy() * std + mean)*255).astype(np.uint8()))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PO8CtYUs5j4X"
   },
   "source": [
    "# **Create models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QdP2EkC5j4X"
   },
   "source": [
    "## Several models for training that can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-25T06:25:22.130541Z",
     "iopub.status.busy": "2022-12-25T06:25:22.130046Z",
     "iopub.status.idle": "2022-12-25T06:25:22.138648Z",
     "shell.execute_reply": "2022-12-25T06:25:22.137458Z",
     "shell.execute_reply.started": "2022-12-25T06:25:22.130504Z"
    },
    "id": "ZZ2jG2iB5j4X"
   },
   "outputs": [],
   "source": [
    "class resNet50(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(resNet50, self).__init__()\n",
    "        self.net = models.resnet50(pretrained=True)\n",
    "        \n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = False                \n",
    "        \n",
    "        fc_inputs = self.net.fc.in_features\n",
    "        self.net.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(fc_inputs, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(128, 2),\n",
    "            # torch.nn.LogSoftmax(dim=1) # For using NLLLoss()\n",
    "        )  \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ku3sc2SM5j4X"
   },
   "source": [
    "## Model Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T18:26:27.207778Z",
     "iopub.status.busy": "2022-12-24T18:26:27.207394Z",
     "iopub.status.idle": "2022-12-24T18:26:27.222148Z",
     "shell.execute_reply": "2022-12-24T18:26:27.221075Z",
     "shell.execute_reply.started": "2022-12-24T18:26:27.207747Z"
    },
    "id": "JlYwSdS95j4X"
   },
   "outputs": [],
   "source": [
    "def train_model(model, loss, optimizer, scheduler, num_epochs):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    loss_hist = {'train':[], 'valid':[]}\n",
    "    accuracy_hist = {'train':[], 'valid':[]}\n",
    "    \n",
    "    print('{:<7s}|{:^20s}|{:^20s}|'.format('', 'Train', 'Valid'))\n",
    "    print('{:<7s}|{:>10s}{:>10s}|{:>10s}{:>10s}|'.format('Epoch', 'Loss', 'Acc', 'Loss', 'Acc'))\n",
    "    print('-' * 50)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                dataloader = train_dataloader\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                dataloader = valid_dataloader\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward and backward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    preds = model(inputs)\n",
    "                    loss_value = loss(preds, labels)\n",
    "                    preds_class = preds.argmax(dim=1)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss_value.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss_value.item()\n",
    "                # Running_acc += (preds_class == labels.data).float().mean()\n",
    "                running_acc += (preds_class == labels.data).float().mean().data.cpu().numpy()                \n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            epoch_acc = running_acc / len(dataloader)\n",
    "            if phase == 'train':\n",
    "                print('{:>3d}/{:>3d}|{:>10.4f}{:>10.4f}|'.format(epoch + 1, num_epochs, epoch_loss, epoch_acc), end='')\n",
    "            else:\n",
    "                print('{:>10.4f}{:>10.4f}|'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "            loss_hist[phase].append(epoch_loss)\n",
    "            accuracy_hist[phase].append(epoch_acc)\n",
    "\n",
    "    return model, loss_hist, accuracy_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OJLLDHm5j4X"
   },
   "source": [
    "## Model traning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T18:26:35.312033Z",
     "iopub.status.busy": "2022-12-24T18:26:35.311619Z",
     "iopub.status.idle": "2022-12-24T18:26:35.320721Z",
     "shell.execute_reply": "2022-12-24T18:26:35.318934Z",
     "shell.execute_reply.started": "2022-12-24T18:26:35.311999Z"
    },
    "id": "DM2IuBEk5j4Y"
   },
   "outputs": [],
   "source": [
    "def train_MyModel(model, epoch_num):\n",
    "    print('\\n' + model.__class__.__name__ + ' training with {} epochs started...\\n'.format(epoch_num))\n",
    " \n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=1.0e-3)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    model, losses, accuracies = train_model(model, loss, optimizer, scheduler, num_epochs=epoch_num);\n",
    "    print('\\nModel training finished.')    \n",
    "    \n",
    "    return model, losses, accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LADppBGv5j4Y"
   },
   "source": [
    "# **Trainig**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHy0MJeT5j4Y"
   },
   "source": [
    "## Run traning\n",
    "Ok! We are ready for Model Training!\n",
    "Choose one of them and start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-25T06:25:27.257202Z",
     "iopub.status.busy": "2022-12-25T06:25:27.256771Z",
     "iopub.status.idle": "2022-12-25T06:25:47.516768Z",
     "shell.execute_reply": "2022-12-25T06:25:47.514978Z",
     "shell.execute_reply.started": "2022-12-25T06:25:27.257167Z"
    },
    "id": "n0zcydp-5j4Y",
    "outputId": "5a5af240-d5b3-45c7-f184-c1029ab5100b"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 40\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "model = resNet50()\n",
    "\n",
    "model, losses, accuracies = train_MyModel(model, epoch_num=40)\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "execution": {
     "iopub.execute_input": "2022-12-24T19:08:57.844171Z",
     "iopub.status.busy": "2022-12-24T19:08:57.843710Z",
     "iopub.status.idle": "2022-12-24T19:08:57.868507Z",
     "shell.execute_reply": "2022-12-24T19:08:57.866923Z",
     "shell.execute_reply.started": "2022-12-24T19:08:57.844131Z"
    },
    "id": "bhTpl_ly5j4Y",
    "outputId": "4d8a09c1-40f2-4a27-d495-ef2a208f40f9"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "for experiment_id in accuracies.keys():\n",
    "    plt.plot(accuracies[experiment_id], label=experiment_id)\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch num', fontsize=15)\n",
    "plt.ylabel('Accuracy value', fontsize=15);\n",
    "plt.grid(linestyle='--', linewidth=0.5, color='.7')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.736367Z",
     "iopub.status.idle": "2022-12-24T15:31:05.736678Z",
     "shell.execute_reply": "2022-12-24T15:31:05.736545Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.736531Z"
    },
    "id": "EyVT6Kyg5j4Y",
    "outputId": "a337fde1-1750-407b-a15b-c7e63cf4f585"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "for experiment_id in losses.keys():\n",
    "    plt.plot(losses[experiment_id], label=experiment_id)\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch num', fontsize=15)\n",
    "plt.ylabel('Loss function value', fontsize=15)\n",
    "plt.grid(linestyle='--', linewidth=0.5, color='.7')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3lRt6VR5j4Y"
   },
   "source": [
    "# **Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuTNYArj5j4Y"
   },
   "source": [
    "## Create a Test transformation methods\n",
    "Now we are ready for predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.737476Z",
     "iopub.status.idle": "2022-12-24T15:31:05.737778Z",
     "shell.execute_reply": "2022-12-24T15:31:05.737643Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.737628Z"
    },
    "id": "grmUX_Pn5j4Z"
   },
   "outputs": [],
   "source": [
    "transform_image = {\n",
    "    'to_tensor_and_normalize': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# List of transformation methods\n",
    "transforms_list = { \n",
    "    'original': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "    ]),   \n",
    "#     'crop_220': transforms.Compose([\n",
    "#         transforms.CenterCrop(220),\n",
    "#         transforms.Resize((224, 224)),\n",
    "#     ]), \n",
    "#     'crop_200': transforms.Compose([\n",
    "#         transforms.CenterCrop(200),\n",
    "#         transforms.Resize((224, 224)),\n",
    "#     ]),    \n",
    "    'crop_180': transforms.Compose([\n",
    "        transforms.CenterCrop(180),\n",
    "        transforms.Resize((224, 224)),\n",
    "    ]),    \n",
    "    'crop_160': transforms.Compose([\n",
    "        transforms.CenterCrop(160),\n",
    "        transforms.Resize((224, 224)),\n",
    "    ]),   \n",
    "    'crop_140': transforms.Compose([\n",
    "        transforms.CenterCrop(140),\n",
    "        transforms.Resize((224, 224)),\n",
    "    ]),   \n",
    "#     'crop_120': transforms.Compose([\n",
    "#         transforms.CenterCrop(120),\n",
    "#         transforms.Resize((224, 224)),\n",
    "#     ]),    \n",
    "    'gray_280': transforms.Compose([\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.CenterCrop(280),\n",
    "        transforms.Resize((224, 224)),\n",
    "    ]),\n",
    "    'gray_200': transforms.Compose([\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.CenterCrop(200),\n",
    "        transforms.Resize((224, 224)),\n",
    "    ]),\n",
    "    'r_crop_180_1': transforms.Compose([\n",
    "        transforms.RandomCrop(180),\n",
    "        transforms.Resize((224, 224)),\n",
    "    ]),\n",
    "    'r_crop_180_2': transforms.Compose([\n",
    "        transforms.RandomCrop(180),\n",
    "        transforms.Resize((224, 224)),\n",
    "    ]),\n",
    "    'r_crop_180_3': transforms.Compose([\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.RandomCrop(180),\n",
    "        transforms.Resize((224, 224)),\n",
    "    ]),        \n",
    "}\n",
    "\n",
    "# Test Dataset\n",
    "dataset['test'] = ImageFolderWithPaths(DATA_ROOT + '/test', transform=None)\n",
    "\n",
    "# Test Dataloaders\n",
    "test_dataloader  = torch.utils.data.DataLoader(dataset['test'],\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiLvHX7o5j4Z"
   },
   "source": [
    "## Let's predict the status for one chosen plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.739579Z",
     "iopub.status.idle": "2022-12-24T15:31:05.740016Z",
     "shell.execute_reply": "2022-12-24T15:31:05.739837Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.739818Z"
    },
    "id": "jwOb1AOu5j4Z",
    "outputId": "7445903d-3182-42a9-d129-f5ebf48136dd"
   },
   "outputs": [],
   "source": [
    "img_id = random.randint(20,60)\n",
    "\n",
    "img_original = test_dataloader.dataset[img_id][0]\n",
    "\n",
    "img_id = test_dataloader.dataset[img_id][2]\n",
    "img_id = img_id.replace(DATA_ROOT + '/working/test/unknown/', '')\n",
    "img_id = img_id.replace('.jpg', '')\n",
    "\n",
    "labels = {}\n",
    "labels['id'] = img_id\n",
    "\n",
    "for i, method in enumerate(transforms_list):\n",
    "    img_transformed = transforms_list[method](img_original)\n",
    "    tensor = transform_image['to_tensor_and_normalize'](img_transformed)\n",
    "    tensor = tensor.to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        preds = model(tensor)\n",
    "        \n",
    "    label = torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy()[0]\n",
    "    labels[method] = label\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "for i, method in enumerate(transforms_list):\n",
    "    img_transformed = transforms_list[method](img_original)\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.title(method + ', ' + str(round(labels[method],4)))\n",
    "    plt.imshow(img_transformed); \n",
    "  \n",
    "print('{:3s}{:15s}{:7s}'.format('N', 'Method', 'Percent')), print('-' * 25)\n",
    "for i, method in enumerate([x for x in labels if x != 'id']):\n",
    "    print('{:<3d}{:<15s}{:>7.4f}'.format(i+1, method, labels[method]))\n",
    "print('-' * 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sokdm2JB5j4Z"
   },
   "source": [
    "## Make predictions for all plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.741180Z",
     "iopub.status.idle": "2022-12-24T15:31:05.741565Z",
     "shell.execute_reply": "2022-12-24T15:31:05.741408Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.741392Z"
    },
    "id": "IG4QtqYN5j4Z",
    "outputId": "4590dd56-3e79-475d-c06e-5acd4d14024a"
   },
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "data = []\n",
    "for img_original, labels, img_id in tqdm(test_dataloader.dataset):\n",
    "    labels = {}\n",
    "    labels['id'] = img_id\n",
    "    probs = np.array([])\n",
    "\n",
    "    for i, method in enumerate(transforms_list):\n",
    "        img_transformed = transforms_list[method](img_original)\n",
    "        tensor = transform_image['to_tensor_and_normalize'](img_transformed)\n",
    "        tensor = tensor.to(device)\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            preds = model(tensor)\n",
    "\n",
    "        label = torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy()[0]\n",
    "        labels[method] = label\n",
    "\n",
    "    data.append(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pj9GTwWm5j4Z"
   },
   "source": [
    "# **Submission**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q5r-pVl5j4Z"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.743795Z",
     "iopub.status.idle": "2022-12-24T15:31:05.744553Z",
     "shell.execute_reply": "2022-12-24T15:31:05.744405Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.744385Z"
    },
    "id": "pA21ctgv5j4Z",
    "outputId": "9c4adb05-e30f-477e-bc45-122b6961f36f"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['id'] = df['id'].str.replace(DATA_ROOT + '/test/unknown/', '')\n",
    "df['id'] = df['id'].str.replace('.jpg', '')\n",
    "\n",
    "df.set_index('id', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.745621Z",
     "iopub.status.idle": "2022-12-24T15:31:05.745935Z",
     "shell.execute_reply": "2022-12-24T15:31:05.745804Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.745788Z"
    },
    "id": "3WsXSclI5j4a",
    "outputId": "7105aae3-2f38-42d6-c4f4-8935f1937463"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "for i, col_name in enumerate(df.columns):\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.title(col_name)\n",
    "    plt.hist(x=[df[col_name]], bins=100, histtype='bar');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.747130Z",
     "iopub.status.idle": "2022-12-24T15:31:05.747452Z",
     "shell.execute_reply": "2022-12-24T15:31:05.747324Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.747310Z"
    },
    "id": "UZJvA_6A5j4a"
   },
   "outputs": [],
   "source": [
    "df['original'] = df['original']**(0.6)\n",
    "# df['crop_220'] = df['crop_220']**(2.0)\n",
    "# df['crop_200'] = df['crop_200']**(2.0)\n",
    "df['crop_180'] = df['crop_180']**(2.5)\n",
    "df['crop_160'] = df['crop_160']**(2.5)\n",
    "df['crop_140'] = df['crop_140']**(2.5)\n",
    "# df['crop_120'] = df['crop_120']**(2.0)\n",
    "df['gray_280'] = df['gray_280']**(2.0)\n",
    "df['gray_200'] = df['gray_200']**(2.5)\n",
    "df['r_crop_180_1'] = df['r_crop_180_1']**(2.0)\n",
    "df['r_crop_180_2'] = df['r_crop_180_2']**(2.0)\n",
    "df['r_crop_180_3'] = df['r_crop_180_3']**(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.748351Z",
     "iopub.status.idle": "2022-12-24T15:31:05.748640Z",
     "shell.execute_reply": "2022-12-24T15:31:05.748518Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.748504Z"
    },
    "id": "I0EoZgiw5j4a"
   },
   "outputs": [],
   "source": [
    "for col_name in df.columns:\n",
    "    gap = 0.05\n",
    "    plates_min = 999\n",
    "\n",
    "    for i in range(40, 70):\n",
    "        plates_num = df[(df[col_name] > i/100) & (df[col_name] < i/100 + gap)][col_name].count()\n",
    "        if plates_min > plates_num:\n",
    "            plates_min = plates_num\n",
    "            middle = i/100\n",
    "\n",
    "    df[col_name] = df[col_name] - middle + gap/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.749788Z",
     "iopub.status.idle": "2022-12-24T15:31:05.750089Z",
     "shell.execute_reply": "2022-12-24T15:31:05.749958Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.749943Z"
    },
    "id": "UlS0rHFe5j4a",
    "outputId": "6c866a28-2d0c-406d-812c-921f8eb84ab1"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "for i, col_name in enumerate(df.columns):\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.title(col_name)\n",
    "    plt.hist(x=[df[col_name]], bins=100, histtype='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dC8WZuem5j4a"
   },
   "source": [
    "## Export submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.750992Z",
     "iopub.status.idle": "2022-12-24T15:31:05.751301Z",
     "shell.execute_reply": "2022-12-24T15:31:05.751152Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.751137Z"
    },
    "id": "JKMdvfQG5j4a",
    "outputId": "c4f42500-7ff3-411f-f05e-59d34e3a0aa1"
   },
   "outputs": [],
   "source": [
    "df['mean'] = df.mean(axis=1) # среднее по всем данным(оригинал + обрезанные версии)\n",
    "df['label'] = df['mean'].map(lambda x: 'cleaned' if x < 0 else 'dirty')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.752214Z",
     "iopub.status.idle": "2022-12-24T15:31:05.752843Z",
     "shell.execute_reply": "2022-12-24T15:31:05.752709Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.752693Z"
    },
    "id": "AFH-IgWP5j4a",
    "outputId": "baaddcc5-f977-4f8e-b397-4eefc52e1f5a"
   },
   "outputs": [],
   "source": [
    "#оставили только label\n",
    "df.drop(df.columns[:-1], axis='columns', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANeE5ZFTj8Iu"
   },
   "outputs": [],
   "source": [
    "! rm -rf submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.753806Z",
     "iopub.status.idle": "2022-12-24T15:31:05.754084Z",
     "shell.execute_reply": "2022-12-24T15:31:05.753961Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.753947Z"
    },
    "id": "pwUhw0LW5j4a"
   },
   "outputs": [],
   "source": [
    "file_name = model.__class__.__name__ +'_Seed' + str(seed)\n",
    "df.to_csv('submission.csv')\n",
    "print(\"Result: \" +  file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-24T15:31:05.754844Z",
     "iopub.status.idle": "2022-12-24T15:31:05.755140Z",
     "shell.execute_reply": "2022-12-24T15:31:05.755008Z",
     "shell.execute_reply.started": "2022-12-24T15:31:05.754994Z"
    },
    "id": "bLF9651b5j4b"
   },
   "outputs": [],
   "source": [
    "! rm -rf train valid test plates working plates.zip"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9b153a77af382878c7705eaa84aab7890d2ead923280b2bdda777566b8f1280"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
